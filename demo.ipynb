{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.lix.polytechnique.fr/~hermann/conf.php\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deadline_ahead_list(data):\n",
    "  tbody = data.find('tbody')\n",
    "  rows = tbody.find_all('tr')\n",
    "  conference_array = []\n",
    "  if len(rows) == 0: return conference_array\n",
    "  for row in rows:\n",
    "      cells = row.find_all('td')\n",
    "      name = cells[0].find('a').text.strip() \n",
    "      conference_link = cells[0].find('a')['href']\n",
    "      description = cells[0].find('span', class_='tooltiptext').text.strip() if cells[0].find('span', class_='tooltiptext') is not None else \"\"\n",
    "      location = cells[1].text.strip()\n",
    "      deadline = cells[2].text.strip()\n",
    "      date = cells[3].text.strip()\n",
    "      notification = cells[4].text.strip()\n",
    "      subformat_details =re.sub(r'\\s+', ' ',  cells[5].text.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "      conference_array.append({'name':name, 'conference_link':conference_link,'description':description, 'location':location, 'deadline':deadline, 'date':date, 'notification':notification,'subformat_details':subformat_details})\n",
    "  return conference_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_list(data):\n",
    "  tbody = data.find('tbody')\n",
    "  rows = tbody.find_all('tr')\n",
    "  conference_array = []\n",
    "  if len(rows) == 0: return conference_array\n",
    "  for row in rows:\n",
    "      cells = row.find_all('td')\n",
    "      name = cells[0].find('a').text.strip()\n",
    "      conference_link = cells[0].find('a')['href']\n",
    "      location = cells[1].text.strip()\n",
    "      date = cells[2].text.strip()\n",
    "      remark =re.sub(r'\\s+', ' ',  cells[3].text.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "      conference_array.append({'name':name, 'conference_link':conference_link,  'location':location, 'date':date, 'remark':remark})\n",
    "  return conference_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deadline_over_list(data):\n",
    "  tbody = data.find('tbody')\n",
    "  rows = tbody.find_all('tr')\n",
    "  conference_array = []\n",
    "  if len(rows) == 0: return conference_array\n",
    "  for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    name = cells[0].find('a').text.strip()\n",
    "    conference_link = cells[0].find('a')['href']\n",
    "    location = cells[1].text.strip()\n",
    "    date = cells[2].text.strip()\n",
    "    notification = cells[3].text.strip()\n",
    "    final_version = cells[4].text.strip()\n",
    "    early_registration = cells[5].text.strip()\n",
    "    remarks = re.sub(r'\\s+', ' ',  cells[6].text.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "    conference_array.append({'name':name,'conference_link':conference_link,'location':location,'date':date,'notification':notification,'final_version':final_version,'early_registration':early_registration,'remarks':remarks})\n",
    "  return conference_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def planning_conference_list(data):\n",
    "  tbody = data.find('tbody')\n",
    "  rows = tbody.find_all('tr')\n",
    "  conference_array = []\n",
    "  if len(rows) == 0: return conference_array\n",
    "  for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    name = cells[0].find('a').text.strip()\n",
    "    conference_link = cells[0].find('a')['href']\n",
    "    year = cells[1].text.strip()\n",
    "    location = cells[2].text.strip()\n",
    "    starting_date = cells[3].text.strip()\n",
    "    ending_date = cells[4].text.strip()\n",
    "    remarks = re.sub(r'\\s+', ' ',  cells[5].text.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "    conference_array.append({'name':name,'conference_link':conference_link,'year':year,'location':location,'starting_date':starting_date,'ending_date':ending_date,'remarks':remarks})\n",
    "  return conference_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadline_ahead_conference_arr = []\n",
    "running_conference_arr = []\n",
    "deadline_over_future_conference_arr = []\n",
    "planning_conference_arr = []\n",
    "if(response.status_code == 200):\n",
    "  soup = BeautifulSoup(response.content,'html.parser')\n",
    "  tables = soup.find_all('table', class_=\"conference\")\n",
    "  deadline_ahead = tables[0]\n",
    "  running = tables[1]\n",
    "  deadline_over_future = tables[2] \n",
    "  planning_conference = tables[3]\n",
    "  deadline_ahead_conference_arr = deadline_ahead_list(deadline_ahead)\n",
    "  running_conference_arr = running_list(running)\n",
    "  deadline_over_future_conference_arr = deadline_over_list(deadline_over_future)\n",
    "  planning_conference_arr = planning_conference_list(planning_conference)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def write_csv(data, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = data[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(deadline_ahead_conference_arr,\"demo.json\")\n",
    "write_csv(deadline_ahead_conference_arr,\"demo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yaml\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL chứa dữ liệu YAML\n",
    "url = \"https://ccfddl.github.io/conference/allconf.yml\"\n",
    "\n",
    "# Tải nội dung từ URL\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "\n",
    "# Chuyển đổi từ YAML thành JSON\n",
    "yaml_data = yaml.safe_load(data)\n",
    "json_data = json.dumps(yaml_data, indent=4)\n",
    "\n",
    "# Ghi vào tệp JSON\n",
    "with open(\"allconf.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "with open('allconf.yml', 'w') as file:\n",
    "        try:\n",
    "            yaml.dump(yaml_data, file)\n",
    "        except yaml.YAMLError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã chuyển đổi thành công từ YAML thành CSV và lưu vào tệp allconf.csv\n"
     ]
    }
   ],
   "source": [
    "# Đọc nội dung từ tệp YAML\n",
    "with open(\"allconf.yml\", \"r\") as yaml_file:\n",
    "    yaml_data = yaml.safe_load(yaml_file)\n",
    "    \n",
    "# Mở tệp CSV để ghi\n",
    "with open(\"allconf.csv\", \"w\", newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # Viết header\n",
    "    writer.writerow([\"Title\", \"Description\", \"Sub\", \"Rank\", \"DBLP\", \"Year\", \"ID\", \"Link\", \"Abstract Deadline\", \"Deadline\", \"Timezone\", \"Date\", \"Place\"])\n",
    "\n",
    "    # Viết dữ liệu từ YAML vào CSV\n",
    "    for conference in yaml_data:\n",
    "        title = conference[\"title\"]\n",
    "        description = conference[\"description\"]\n",
    "        sub = conference[\"sub\"]\n",
    "        rank = conference[\"rank\"]\n",
    "        dblp = conference[\"dblp\"]\n",
    "        confs = conference[\"confs\"]\n",
    "        for conf in confs:\n",
    "            year = conf[\"year\"]\n",
    "            conf_id = conf[\"id\"]\n",
    "            link = conf[\"link\"]\n",
    "            timeline = conf[\"timeline\"][0]  # Lấy timeline đầu tiên trong trường hợp có nhiều timeline\n",
    "            abstract_deadline = timeline.get(\"abstract_deadline\", \"\")\n",
    "            deadline = timeline.get(\"deadline\", \"\")\n",
    "            timezone = conf[\"timezone\"]\n",
    "            date = conf[\"date\"]\n",
    "            place = conf[\"place\"]\n",
    "            \n",
    "            writer.writerow([title, description, sub, rank, dblp, year, conf_id, link, abstract_deadline, deadline, timezone, date, place])\n",
    "print(\"Đã chuyển đổi thành công từ YAML thành CSV và lưu vào tệp allconf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
